\documentclass[svgnames,12pt,oneside, openright,a4paper]{scrbook}
\usepackage{tikz,blindtext} %%%% Usado para o titulo  de capitulos
\usepackage[T1]{fontenc}
\usepackage{palatino}
\usepackage{chngpage,calc}
\usepackage{hyperref}
\usepackage{kpfonts}
\usepackage[latin1]{inputenc}  %%% Acentos diretamente em Latex
\usepackage{conf}
\usepackage[portuguese, english, brazil]{babel} %%% Define o Idioma
\usepackage{setspace}
\onehalfspacing
\newenvironment{palavraschaves}{\vspace{1cm}\textbf{Palavras Chaves: }}{}
\newenvironment{keywords}{\vspace{1cm}\textbf{Keywords: }}{}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%Margens
\addtolength{\parindent}{-0.2cm}
\setlength{\textheight}{23cm}
\setlength{\textwidth}{15.5cm}
%%%%%%%%%%%%%%%%% Define o Titulo, o autor e o orientador%%%%%
\newcommand{\titulo}{Compressão de Dados e Teoria da Informação}
\newcommand{\orientador}{Profª Dr.ª Cristiane M. Sato}
\newcommand{\autor}{Lucas Silva Amorim\xspace}
\newcommand{\data}{30 de agosto de 2022}
\newcommand{\membroa}{Prof. Dr. Circulando de Souza}
\newcommand{\insta}{ Universidade Federal de .. }
\newcommand{\membrob}{Prof. Dr. Recirculando de Souza }
\newcommand{\instb}{ Universidade Federal de .. }
\usepackage{amssymb,amsmath,theorem}

%%%%%%Teoremas e outros Ambientes
\input{teoremas}


\begin{document}
%%%Insere o Titulo
\input{titulo}
%%% Insere o Sumário
 \tableofcontents
%%%%%%%%%%%%%%%%%
\chapter*{Agradecimento}
Opcional. Agradeço a todos os que me ajudaram na elaboração deste trabalho...


\chapter*{Resumo}

Neste lugar vai um resumo do projeto e objetivos, apresentando os principais resultados;

Conforme as normas NBR 14724:2002 da ABNT, o resumo é elemento obrigatório, constituído de uma seqüência de frases concisas e objetivas e não de uma simples enumeração de tópicos, não ultrapassando 500 palavras, seguido, logo abaixo, das palavras representativas do conteúdo do trabalho, isto é, palavras-chave e/ou descritores.

\palavraschaves{TCC, Trabalho, Modelo}

\chapter*{Abstract}
Versão em língua estrangeira do resumo. Obrigatório, pela ABNT. O título é ABSTRACT, em inglês, RESUMEN, em espanhol castelhano, e RÉSUMÉ, em francês. Sugerimos Inglês.

\keywords{aubergine,carrot, radish} %%Palavras Chaves em Inglês
\chapter{Introdução}
Esta pesquisa pretende mostrar que [ ... ] através de [ ... ] conforme concepções apresentadas por  [ ... ] . Para isso, articulamos o conceito de  [ ... ]  com o conceito de  [ ... ] . Fizemos pesquisas de recepção conforme  [ ... ] . Articulamos os resultados a partir de idéias de  [ ... ] . ``Neste primeiro parágrafo você deve deixar completamente claro o que pretende com o trabalho. A introdução é redigida depois de escrito todo o trabalho porque, no decorrer da pesquisa, algumas coisas podem ser modificadas em relação ao projeto original''. 
``Depois, em vários parágrafos, você deve falar sobre a problematização, a contextualização histórica, a revisão bibliográfica, os objetivos, a justificativa, a metodologia. As conclusões, evidentemente, devem ficar no capítulo Considerações Finais, para que o leitor não perca o interesse pelo seu trabalho ?. Toda a introdução é feita sem subtítulos, em texto normal''.

\chapter{Conceitos e definições fundamentais}
Este capítulo apresenta algumas definições e conceitos fundametais para o entendimeto das técnicas de compressão que serão discutidas em capítulos posteriores.

\section{Código}

Um \textbf{código} \emph{C} mapeia uma \textbf{mensagem} \emph{m} $\in$ \emph{M} para uma cadeia de \textbf{palavras código} em \emph{$W^+$},onde \emph{M} é chamado \textbf{alfabeto de origem} e \emph{$W^+$} \textbf{alfabeto de palavras código}. Vamos utiliar a notação $\emph{A}^+$ para se referir ao conjunto que contém todas as cadeias de \emph{A}, \emph{i.e}, $\emph{A}^+ = \bigcup_{i \geq 1}^{}A^{i} : A^i = (a_1,...,a_i), a \in A $. Deste modo, podemos representar um código como uma função \textbf{\emph{C} : $\emph{M} \rightarrow \emph{W}^+$}.

Os elementos dos alfabetos de origem e de palavras código podem ter um comprimento fixo ou variável. Códigos nos quais os alfabetos possuem um comprimento fixo são chamados de \textbf{códigos de comprimento fixo}, enquanto os que possuem alfabetos de comprimento variáveis são chamados \textbf{códigos de comprimento váriavel}. Provavelmente o exemplo mais conhecido de código de comprimento fixo seja código ASCII, que mapeia 64 simbolos alfa-númericos (ou 256 em sua versão extendida) para palavras código de 8 bits. Todavia, a compressão de dados utiliza apenas códigos de comprimento variável, mas especificamente códigos que variam o comprimento de acordo com a probabilidade associada à mensagem (o tema será melhor detalhado em seções posteriores). 


\subsection{Códigos unicamente decodificáveis e livres de prefixo}
Um código é \textbf{distinto} se pode ser representado como uma função \textbf{bijetora}, i.e, $\forall$ $m_1$, $m_2$ $\in$ M, \emph{C($m_1$)} $\neq$ \emph{C($m_2$)}. Um código é dito \textbf{unicamente decodificável} quando \emph{C(m)} = $w^n$ $\leftrightarrow$ \emph{$C^{-1}(w^n)$} = \emph{m}, com \emph{m} $\in$ \emph{M} e \emph{$w^n$} $\in$ $W^+$.

Vamos definir \emph{$C^+$} como a \textbf{codificação} correspondente ao código \emph{C}, tal que $C^+(m^n) = C(m_1)C(m_2)...C(m_n) : m^n = m_1m_2...m_n$, \emph{i.e}, \emph{$C^+ : M^+ \rightarrow W^+$}. A função de \textbf{decodificação} \emph{$D^+ : W^+ \rightarrow M^+$} se refere a operação inversa da codificação, de modo que dado um código \textbf{unicamente decodificável} \emph{C}, $D^+(C^+(m^n)) = m^n$. 

Um \textbf{código livre de prefixo} é um código \emph{C'} em que $\nexists w_1^n, w_2^n \in W^+$ $|$ $w_1^n$ é \textbf{prefixo} de $w_2^n$, por exemplo, o conjunto de palavras código \emph{$W^+$} := $\{1, 01, 000, 001\}$ não possui nenhuma cadeia que é prefixo de outra dentro do conjunto. Códigos livres de prefixo podem ser \emph{decodificados instantaneamente}, ou seja, podemos decodificar uma palavra código sem precisar verificar o início da seguinte.

\begin{teo}
Todo código \textbf{livre de prefixo} é \textbf{unicamente decodificável}.

\begin{proof}
Seja C um código livre de prefixo e $S_n$ = $s_1...s_n$ uma mensagem codificada por C. Vamos provar por indução que o teorema é verdadeiro para todo n $\in$ $\mathbb{Z+}$

\item \textbf{Casos base}: Quando n = 1, a mensagem S só possui uma palavra código, logo é unicamente decodificável. Se n = 2, então S possui uma palavra código $s_1$ que não pode ser prefixo de $s_2$ (pela própria definição de códigos livres de prefixo), o que claramente significa que S é unicamente decodificável.

\item \textbf{Passo indutivo}: Seja k $\in$ $\mathbb{Z+}$, e suponha por hipótese de indução que o teorema vale para n $\leq$ k. Como $S_{k+1}$ é livre de prefixo, existe um prefixo de $S_{k+1}$, $S_j$ = $s_1...s_j$ (com j $\leq$ k + 1) que é unicamente decodificável (dado que ela não pode ser prefixo de nenhuma outra). a mensagem $S'_{k+1}$ = $s_{j+1}...s_{k+1}$ ainda é uma concatenação decodificável e |$S'_{k+1}$| $\leq$ |$S_{k+1}$|, o que significa que por hipótese de indução $S'_{k+1}$ é unicamente decodificável. Como $S_{k+1}$ = $S_j$ $S'_{k+1}$, segue que $S_{k+1}$ é unicamente decodificável.
\end{proof}
\end{teo}

\section{Relações fundamentais com a Teoria da Informação}
A codificação é comumente divida em duas componenetes diferentes: \emph{modelo} e \emph{codificador}. O \emph{modelo} identifica a distribuição de probabilidade das mensagens baseado em sua semântica e estrutura. O \emph{codificador} toma vantagem de um possível \emph{bias} apontado pela modelagem, e usa uma estratégia gulosa em relação a probabilidade associada às mensagens para reduzir seu tamanho. (substituindo as mensagens que ocorrem com maior frequência por símbolos menores).

Desta forma, é evidente que os algoritmos de compressão sempre devem tomar vantagem de alguma distribuição de probabilidades "desbalanceada" sobre as mensagens para efetivamente reduzir o tamanho destas, ou seja, a compressão é fortemente relacionada com a probabilidade. Nesta seção, vamos construir o embasamento teórico necessário para entender a relação entre as probabilidades associadas e o comprimento das mensagens, e consequentemente criar uma noção dos parametros que devem ser maximizados para alcançar uma codificação eficiente.

\subsection{Distribuição de Probabilidade e Esperança}
Dado um experimento e um espaço amostral $\Omega$, uma \textbf{variável aleatória} \emph{X} associa um número real a cada um dos possíveis resultados em $\Omega$. Em outras palavras, \emph{X} é uma função que mapeia os elementos do espaço amostral para números reais. Quando a imagem de \emph{X} pode assumir um número finito de valores, dizemos que \emph{X} é uma \textbf{variável aleatória discreta}.

Podemos descrever melhor uma variável aleatória, atribuindo probabilidades sobre os valores que esta pode assumir. Esses valores são atribuídos pela \textbf{função de densidade de probabilidade}, denotada por \emph{$p_X$}. Portanto, a probabilidade do evento \{ \emph{X} = \emph{x} \} é a função de distribuição de probabilidade aplicada a x, \emph{i.e}, \emph{$p_X(x)$}.
\begin{equation*}
p_X(x) = P({X = x})
\end{equation*}

Note que, a variável aleatória pode assumir qualquer um dos valores no espaço amostral que possuem uma probabilidade $\emph{P} > 0$.
\begin{equation*}
\sum_{x}^{}p_X(x) = 1
\end{equation*}
%%%%%%%%%%%%%%%%%%%BIbliografia
\begin{thebibliography}{9999}  
\bibitem[HL]{D.S Hirschberg}HIRSCHBERG, D.S; LELEWER D.A;
\emph{Data compression, }Computing Surveys 19.3, 1987.

\bibitem[Ble]{Guy E. Blelloch}BLELLOCH G.E;
\emph{Introduction to Data Compression, } Carnegie Mellon, 2013

\bibitem[BT]{Dimitri P. Bertsekas} BERTSEKAS D.P; TSITSIKLIS J.N;
\emph{Introduction to Probability} M.I.T, Lecture Notes Course 6.041-6.431, 2000

\end{thebibliography}

\end{document}
